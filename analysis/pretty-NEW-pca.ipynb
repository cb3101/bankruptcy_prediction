{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year $N$\n",
    "Run all in this section..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = '5'\n",
    "drop_cols = ['Attr37', 'Attr7','Attr43','Attr62','Attr32','Attr44','Attr15','Attr19','Attr3','Attr51','Attr4','Attr49','Attr38','Attr60','Attr6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arff = loadarff(data_path+N+'year.arff')\n",
    "df = pd.DataFrame(arff[0])\n",
    "df['class']= df['class'].astype('int')\n",
    "df = df.drop_duplicates()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dropcols accordingly...\n",
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop_cols,axis='columns')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain NaN in test set also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class',axis='columns')\n",
    "Y = df['class']\n",
    "# (X.shape,Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=random_state,shuffle=True,stratify=Y)\n",
    "\n",
    "display(Y_train.value_counts(), Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test = X_train.to_numpy(),Y_train.to_numpy(),X_test.to_numpy(),Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "simple_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simple_imp = simple_imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp = simple_imp.transform(X_train)\n",
    "X_test_imp = simple_imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "pca = pca.fit(X_train_imp)\n",
    "\n",
    "X_train_imp = pca.transform(X_train_imp)\n",
    "X_test_imp = pca.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose imputer <<comment blocks accordingly>>\n",
    "\n",
    "#### for simple\n",
    "scaled_already = False\n",
    "# X_train_imp = simple_imp.transform(X_train)\n",
    "# X_test_imp = simple_imp.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier # Voting Ensemble for Classification\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_classifiers(X_train, X_test, y_train, y_test, classifiers, sampling  = None, scaler=None):\n",
    "    '''\n",
    "    do all imputations before passing here...\n",
    "    Classifier : array of tuples (classifier,scaling required=True/False)\n",
    "    '''\n",
    "    accuracy = [0]*len(classifiers)\n",
    "    f1 = [0]*len(classifiers)\n",
    "    precision = [0]*len(classifiers)\n",
    "    recall = [0]*len(classifiers)\n",
    "    i = 0\n",
    "    \n",
    "    model_pipeline = []\n",
    "    Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    if sampling == \"SMOTE\":\n",
    "        model_pipeline.append(('sampling', SMOTE(sampling_strategy=0.6,random_state=random_state) ))\n",
    "        # X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTE\")\n",
    "    if sampling == \"RUS\":\n",
    "        model_pipeline.append(('sampling', RandomUnderSampler(sampling_strategy=0.6,random_state=random_state) ))\n",
    "        # X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"RUS\")\n",
    "    if sampling == \"SMOTEENN\":\n",
    "        model_pipeline.append(('sampling', SMOTEENN(sampling_strategy=0.6,random_state=random_state) ))\n",
    "        # X_train, y_train = smoteenn.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTEENN\")    \n",
    "\n",
    "    voting_classifs = []\n",
    "    models_for_voting = [0,3,5,6,7,8]\n",
    "    voting_weights = [1,0.5,1,0.5,1,1]\n",
    "    jj =0 \n",
    "        \n",
    "    for i in range(len(classifiers)):\n",
    "        classif = classifiers[i][0]\n",
    "        pipe_parameters = classifiers[i][2]\n",
    "        y_pred = []\n",
    "        print(classifiers_names[i])\n",
    "        pipeline = Pipeline(model_pipeline+[('classifier',classif)])\n",
    "        \n",
    "        if classifiers[i][1] and not scaled_already:\n",
    "            print(\"\\t- Requires scaling and not scaled. Doing it now...\")\n",
    "            grid = GridSearchCV(pipeline, pipe_parameters, cv=2, scoring=\"f1\",n_jobs=-1,verbose=1)\n",
    "            #grid = grid.fit(X_train, y_train)\n",
    "            grid = grid.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "            #classif.fit(scaler.transform(X_train), y_train)\n",
    "            #y_pred = classif.predict(scaler.transform(X_test))\n",
    "            \n",
    "            display(grid.best_params_)\n",
    "            classif = grid.best_estimator_\n",
    "            y_pred = grid.predict(scaler.transform(X_test))\n",
    "            #classif.fit(scaler.transform(), )\n",
    "            #y_pred = classif.predict(scaler.transform(X_test))\n",
    "            \n",
    "        else:\n",
    "            grid = GridSearchCV(pipeline, pipe_parameters, cv=2, scoring=\"f1\",n_jobs=-1,verbose=1)\n",
    "            grid.fit(X_train, y_train)\n",
    "            display(grid.best_params_)\n",
    "            classif = grid.best_estimator_\n",
    "            y_pred = grid.predict(X_test)\n",
    "            \n",
    "            #classif.fit(X_train, y_train)\n",
    "            #y_pred = classif.predict(X_test)\n",
    "        \n",
    "        if i in models_for_voting:\n",
    "            print(\"\\t- Adding for voting with weight <\"+str(voting_weights[jj])+\">...\")\n",
    "            jj+=1\n",
    "            voting_classifs.append((\"mod\"+str(i+1),classif))\n",
    "        \n",
    "        accuracy[i] = metrics.accuracy_score(y_test, y_pred)\n",
    "        f1[i] = metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "        precision[i] = metrics.precision_score(y_test, y_pred)\n",
    "        recall[i] = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n\\nVoting...\")\n",
    "    # create the ensemble model\n",
    "    ensemble = VotingClassifier(voting_classifs,weights=voting_weights,n_jobs=-1,voting=\"hard\")\n",
    "    ensemble.fit(scaler.transform(X_train), y_train)\n",
    "    y_pred = ensemble.predict(scaler.transform(X_test))\n",
    "    \n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    f1.append(metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred)))\n",
    "    precision.append(metrics.precision_score(y_test, y_pred))\n",
    "    recall.append(metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "    print(\"Done\")\n",
    "    return accuracy,f1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers_voting = [('log',LogisticRegression(max_iter=2048)),(\"knn10\",KNeighborsClassifier(n_neighbors=10)),(\"dtc\",DecisionTreeClassifier()),(\"svm_linear\",SVC(kernel='linear',random_state=random_state)),(\"rf\",RandomForestClassifier(n_estimators=16, n_jobs=8, random_state=random_state)),(\"xbg\",XGBClassifier(use_label_encoder=False))]\n",
    "# classifiers_voting = [(\"dtc\",DecisionTreeClassifier()),(\"rf\",RandomForestClassifier(n_estimators=64, n_jobs=-1, random_state=random_state)),(\"xbg\",XGBClassifier(use_label_encoder=False))]\n",
    "\n",
    "classifiers_names = [\"LR\", \"LDA\", \"KNN-5\", \"KNN-10\", \"GNB\", \"DT\", \"SVC\", \"RFC\", \"XGB\",\"Voting\"]\n",
    "\n",
    "classifiers = [(LogisticRegression(max_iter=2048,random_state=random_state),True,\n",
    "                   [\n",
    "                       #{\n",
    "                       # 'classifier__penalty' : ['l1', 'l2'],\n",
    "                       # 'classifier__C' : np.logspace(-8, 4, 16),\n",
    "                       # 'classifier__solver' : ['liblinear']\n",
    "                       # },\n",
    "                        {\n",
    "                        'classifier__penalty' : ['l2','none'],\n",
    "                        'classifier__C' : np.logspace(-8, 4, 16)\n",
    "                        }\n",
    "                   ]),\n",
    "                (LinearDiscriminantAnalysis(),True,\n",
    "                    { 'classifier__solver' : ['svd', 'lsqr', 'eigen'] }),\n",
    "                (KNeighborsClassifier(n_neighbors=5),True,\n",
    "                    {'classifier__weights' : ['uniform','distance'], 'classifier__metric' : ['euclidean', 'manhattan']}), \n",
    "                (KNeighborsClassifier(n_neighbors=10),True,\n",
    "                    {'classifier__weights' : ['uniform','distance'], 'classifier__metric' : ['euclidean', 'manhattan']}),\n",
    "                (GaussianNB(),True,\n",
    "                    {'classifier__var_smoothing': np.logspace(0,-9, num=100)}),\n",
    "                (DecisionTreeClassifier(random_state=random_state),False,\n",
    "                    { 'classifier__criterion':['gini','entropy'],'classifier__max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]} ),\n",
    "                (SVC(random_state=random_state),True,\n",
    "                    [\n",
    "                        {'classifier__C': [ 0.05, 0.1, 1], \n",
    "                         'classifier__gamma': [0.0001, 1],\n",
    "                         'classifier__kernel': ['rbf']},\n",
    "                        {'classifier__C': [ 0.05, 0.1, 1],\n",
    "                         'classifier__kernel': ['linear']}\n",
    "                    ]),\n",
    "                (RandomForestClassifier(random_state=random_state),False,\n",
    "                     { 'classifier__n_estimators': [int(x) for x in np.linspace(start = 128, stop = 512, num = 4)],\n",
    "                       'classifier__max_features': ['auto'],\n",
    "                       'classifier__max_depth':  [int(x) for x in np.linspace(10, 100, num = 2)]+[None],\n",
    "                       'classifier__min_samples_leaf':  [1, 4],\n",
    "                       'classifier__bootstrap': [False]\n",
    "                     }),\n",
    "                (XGBClassifier(use_label_encoder=False),False,\n",
    "                    {\n",
    "                        'classifier__gamma': [0.5, 1, 2, 5],\n",
    "                        'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                        'classifier__max_depth': [3, 6]\n",
    "                    }) ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy,f1,precision,recall = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sm,f1_sm,precision_sm,recall_sm = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTE\", scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rus,f1_rus,precision_rus,recall_rus = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"RUS\", scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_smoteenn,f1_smoteenn,precision_smoteenn,recall_smoteenn = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTEENN\",scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imputer & Sampling & Metric & \",end = \"\")\n",
    "print(*classifiers_names,sep = \" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"\\\\hline \\\\hline\")\n",
    "print(\"Simple & No & Acc & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in accuracy],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Prec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in precision],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Rec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in recall],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & F1 & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in f1],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"\\cline{2-13}\")\n",
    "\n",
    "print(\"~ & SMOTE & Acc & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in accuracy_sm],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Prec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in precision_sm],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Rec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in recall_sm],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & F1 & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in f1_sm],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"\\cline{2-13}\")\n",
    "\n",
    "print(\"~ & RUS & Acc & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in accuracy_rus],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Prec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in precision_rus],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Rec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in recall_rus],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & F1 & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in f1_rus],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"\\cline{2-13}\")\n",
    "\n",
    "\n",
    "print(\"~ & SMOTE- & Acc & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in accuracy_smoteenn],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ENN & Prec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in precision_smoteenn],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & Rec & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in recall_smoteenn],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"~ & ~ & F1 & \",end=\"\")\n",
    "print(*['%.2f' % elem for elem in f1_smoteenn],sep=\" & \", end = \" \\\\\\\\\\n\")\n",
    "print(\"\\\\hline\\\\hline\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "| classifier          | Accuracy | Precision | Recall | F1 score |\n",
    "| =================== | ======== | ========= | ====== | ======== |''')\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy,precision,recall,f1):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "    \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_sm,precision_sm,recall_sm,f1_sm):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "\n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_rus,precision_rus,recall_rus,f1_rus):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "  \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_smoteenn,precision_smoteenn,recall_smoteenn,f1_smoteenn):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------\n",
    "# EOF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
