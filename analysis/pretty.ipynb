{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install scikit-learn==0.20.1  # dep for missingpy\n",
    "#!pip3 install scikit-learn==0.24.1  # required for getting tree diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year $N$\n",
    "Run all in this section..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = '5'\n",
    "drop_cols = ['Attr37', 'Attr7','Attr43','Attr62','Attr32','Attr44','Attr15','Attr19','Attr3','Attr51','Attr4','Attr49','Attr38','Attr60','Attr6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arff = loadarff(data_path+N+'year.arff')\n",
    "df = pd.DataFrame(arff[0])\n",
    "df['class']= df['class'].astype('int')\n",
    "df = df.drop_duplicates()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dropcols accordingly...\n",
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop_cols,axis='columns')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain NaN in test set also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class',axis='columns')\n",
    "Y = df['class']\n",
    "# (X.shape,Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=random_state,shuffle=True,stratify=Y)\n",
    "\n",
    "display(Y_train.value_counts(), Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test = X_train.to_numpy(),Y_train.to_numpy(),X_test.to_numpy(),Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "#scaler = None\n",
    "\n",
    "#idx = np.isnan(X_train).any(axis=1)\n",
    "#scaler = StandardScaler().fit(X_train[~idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imputer(imputer_estimator,X_train,Y_train,transform_x=True,reset_index = True,verbose=True,max_iter=10,tol=1,imputer=None,scaler=None):\n",
    "    # train = pd.concat([X_train,Y_train],axis=1)\n",
    "    # train['class'] = train['class'].astype('category')\n",
    "    # if reset_index:\n",
    "    #     train = train.reset_index(drop=True)\n",
    "    \n",
    "    if imputer is None:\n",
    "        imputer = IterativeImputer(estimator=imputer_estimator, n_nearest_features=None, imputation_order='descending',verbose=verbose,max_iter=max_iter,tol=tol)\n",
    "        imputer = imputer.fit(X_train,Y_train)\n",
    "    else:\n",
    "        imputer = imputer.fit(X_train,Y_train)\n",
    "        \n",
    "    \n",
    "    if transform_x:\n",
    "        X_train = imputer.transform(X_train)\n",
    "        \n",
    "        #if scaler is not None:\n",
    "        #    X_train = scaler.transform(X_train)\n",
    "        \n",
    "        return imputer,X_train\n",
    "    \n",
    "    return imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missingpy import MissForest\n",
    "\n",
    "missf_imp = MissForest(random_state=random_state,verbose=1,n_jobs=4)\n",
    "missf_imp,X_train_imp = build_imputer(None,X_train,Y_train,transform_x=True,imputer=missf_imp)\n",
    "X_test_imp = missf_imp.transform(X_test)\n",
    "\n",
    "# note... these are not scaled!!\n",
    "np.save(\"y\"+N+\"_realmissforest_train.npy\",X_train_imp)\n",
    "np.save(\"y\"+N+\"_realmissforest_test.npy\",X_test_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# has to be scaled...\n",
    "knn_imp = build_imputer( KNeighborsRegressor(n_jobs=4) ,scaler.transform(X_train),Y_train,transform_x=False,reset_index = True,verbose=True,max_iter=64,tol=0.009,scaler=scaler)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "simple_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simple_imp = simple_imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose imputer <<comment blocks accordingly>>\n",
    "\n",
    "#### for simple\n",
    "scaled_already = False\n",
    "X_train_imp = simple_imp.transform(X_train)\n",
    "X_test_imp = simple_imp.transform(X_test)\n",
    "\n",
    "################################# OR ################################\n",
    "'''\n",
    "#### for KNN\n",
    "scaled_already = True\n",
    "X_train_imp = knn_imp.transform(scaler.transform(X_train))\n",
    "X_test_imp = knn_imp.transform(scaler.transform(X_test))\n",
    "'''\n",
    "################################# OR ################################\n",
    "'''\n",
    "#### for missf, use saved files...\n",
    "scaled_already = False\n",
    "X_train_imp = np.load(\"y\"+N+\"_realmissforest_train.npy\")\n",
    "X_test_imp = np.load(\"y\"+N+\"_realmissforest_test.npy\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier # Voting Ensemble for Classification\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_classifiers(X_train, X_test, y_train, y_test, classifiers, sampling  = None, scaler=None):\n",
    "    '''\n",
    "    do all imputations before passing here...\n",
    "    Classifier : array of tuples (classifier,scaling required=True/False)\n",
    "    '''\n",
    "    accuracy = [0]*len(classifiers)\n",
    "    f1 = [0]*len(classifiers)\n",
    "    precision = [0]*len(classifiers)\n",
    "    recall = [0]*len(classifiers)\n",
    "    i = 0\n",
    "    \n",
    "    if sampling == \"SMOTE\":\n",
    "        smote = SMOTE(sampling_strategy=0.6,random_state=random_state,n_jobs=4)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTE\")\n",
    "    if sampling == \"RUS\":\n",
    "        rus = RandomUnderSampler(sampling_strategy=0.6,random_state=random_state)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"RUS\")\n",
    "    if sampling == \"SMOTEENN\":\n",
    "        smoteenn = SMOTEENN(sampling_strategy=0.6,random_state=random_state,n_jobs=4)\n",
    "        X_train, y_train = smoteenn.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTEENN\")    \n",
    "        \n",
    "    \n",
    "    for i in range(len(classifiers)):\n",
    "        classif = classifiers[i][0]\n",
    "        y_pred = []\n",
    "        print(classifiers_names[i])\n",
    "        \n",
    "        if classifiers[i][1] and not scaled_already:\n",
    "            print(\"\\t- Requires scaling and not scaled. Doing it now...\")\n",
    "            classif.fit(scaler.transform(X_train), y_train)\n",
    "            y_pred = classif.predict(scaler.transform(X_test))\n",
    "            \n",
    "        else:\n",
    "            classif.fit(X_train, y_train)\n",
    "            y_pred = classif.predict(X_test)\n",
    "        \n",
    "        accuracy[i] = classif.score(X_test, y_test)\n",
    "        f1[i] = metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "        precision[i] = metrics.precision_score(y_test, y_pred)\n",
    "        recall[i] = metrics.recall_score(y_test, y_pred)\n",
    "    print(\"Done\")\n",
    "    return accuracy,f1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_voting = [('log',LogisticRegression(max_iter=2048)),(\"knn10\",KNeighborsClassifier(n_neighbors=10)),(\"dtc\",DecisionTreeClassifier()),(\"svm_linear\",SVC(kernel='linear',random_state=random_state)),(\"rf\",RandomForestClassifier(n_estimators=16, n_jobs=8, random_state=random_state)),(\"xbg\",XGBClassifier(use_label_encoder=False))]\n",
    "# classifiers_voting = [(\"dtc\",DecisionTreeClassifier()),(\"rf\",RandomForestClassifier(n_estimators=64, n_jobs=8, random_state=random_state)),(\"xbg\",XGBClassifier(use_label_encoder=False))]\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(classifiers_voting,weights=[1,1,1,1,1,2],n_jobs=4,voting=\"hard\")\n",
    "\n",
    "\n",
    "classifiers_names = [\"Logistic Regression\", \"LDA\", \"KNN 5\", \"KNN 10\", \"GNB\", \"DT\", \"SVM\", \"RFC\", \"XGB\",\"Voting\"]\n",
    "classifiers = [(LogisticRegression(max_iter=2048),True), \n",
    "                (LinearDiscriminantAnalysis(),True),\n",
    "                (KNeighborsClassifier(n_neighbors=5),True), \n",
    "                (KNeighborsClassifier(n_neighbors=10),True),\n",
    "                (GaussianNB(),True),\n",
    "                (DecisionTreeClassifier(random_state=random_state),False),\n",
    "                (SVC(kernel='linear',random_state=random_state),True),\n",
    "                (RandomForestClassifier(random_state=random_state),False),\n",
    "                (XGBClassifier(use_label_encoder=False),False),\n",
    "                (ensemble,True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,f1,precision,recall = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sm,f1_sm,precision_sm,recall_sm = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTE\", scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rus,f1_rus,precision_rus,recall_rus = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"RUS\", scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_smoteenn,f1_smoteenn,precision_smoteenn,recall_smoteenn = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTEENN\",scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('''\n",
    "| classifier          | Accuracy | Precision | Recall | F1 score |\n",
    "| =================== | ======== | ========= | ====== | ======== |''')\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy,precision,recall,f1):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "    \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_sm,precision_sm,recall_sm,f1_sm):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "  \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_rus,precision_rus,recall_rus,f1_rus):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "  \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_smoteenn,precision_smoteenn,recall_smoteenn,f1_smoteenn):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(y_true,y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Not Bankrupt\",\"Bankrupt\"])\n",
    "    disp = disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    # plt.savefig(dir_+\"/cf_test-epoch\"+str(e+1)+\".png\",transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,X_train,Y_train,X_val,Y_val,X_test,Y_test,report_train_scores=True,impute_test=False,imputer=None,scaler=None):\n",
    "    # pass the imputed train set\n",
    "    \n",
    "    if scaler is not None:\n",
    "        X_train = scaler.transform(X_train)\n",
    "    \n",
    "    model = model.fit(X_train, Y_train)\n",
    "    \n",
    "    if impute_test:\n",
    "        X_test = imputer.transform(X_test)\n",
    "    \n",
    "    # impute -> standardise -> predict\n",
    "    if scaler is not None:\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    build_confusion_matrix(Y_test,y_pred)\n",
    "    \n",
    "    if report_train_scores:\n",
    "        print(\"For train...\")\n",
    "        y_pred = model.predict(X_train)\n",
    "        print(classification_report(Y_train, y_pred))\n",
    "    \n",
    "    # print(y_pred)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "build_model(knn,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=imputer,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecTrees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decTree = DecisionTreeClassifier()\n",
    "build_model(decTree,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=missf,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "# plot_tree(decTree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "build_model(ada,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=missf,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=16)\n",
    "xgb = build_model(xgb,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=missf,scaler=scaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1024)\n",
    "build_model(logistic,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=missf,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada = RandomForestClassifier(n_estimators=16, n_jobs=4, random_state=random_state, verbose=1)\n",
    "build_model(ada,X_train_imp,Y_train,None,None,X_test,Y_test,impute_test=True,imputer=missf,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca = pca.fit(X_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_pca = pca.transform(X_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=16)\n",
    "xgb = build_model(xgb,X_train_imp_pca,Y_train,None,None,pca.transform(knn_imp.transform(X_test)),Y_test,impute_test=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "all_imputers = [ExtraTreesRegressor(n_estimators=16, n_jobs=4, random_state=random_state, verbose=0)]\n",
    "# all_imputers = [KNeighborsRegressor(n_jobs=4),ExtraTreesRegressor(n_estimators=16, n_jobs=4, random_state=random_state, verbose=0),RandomForestRegressor(n_estimators=16, n_jobs=4, random_state=random_state, verbose=0),BayesianRidge(verbose=0)]\n",
    "\n",
    "imputer=None\n",
    "X_train_imp=None\n",
    "\n",
    "for imputer_estimator in all_imputers:\n",
    "    print(imputer_estimator)\n",
    "    imputer,X_train_imp = build_imputer(imputer_estimator,X_train,Y_train,transform_x=True,reset_index = True,verbose=True,max_iter=32,tol=0.01,scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_classifiers(X_train, X_test, y_train, y_test, classifiers, sampling  = None):\n",
    "    accuracy = [0]*len(classifiers)\n",
    "    f1 = [0]*len(classifiers)\n",
    "    precision = [0]*len(classifiers)\n",
    "    recall = [0]*len(classifiers)\n",
    "    i = 0\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=1, shuffle = True)\n",
    "    if sampling == \"SMOTE\":\n",
    "        smote = SMOTE(sampling_strategy=0.6,random_state=random_state,n_jobs=4)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTE\")\n",
    "    if sampling == \"RUS\":\n",
    "        rus = RandomUnderSampler(random_state=random_state,n_jobs=4)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"RUS\")\n",
    "    if sampling == \"SMOTEENN\":\n",
    "        rus = SMOTEENN(sampling_strategy=0.6,random_state=random_state,n_jobs=4)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTEENN\")\n",
    "        \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    for i in range(len(classifiers)):\n",
    "        classif = classifiers[i]\n",
    "        classif.fit(X_train, y_train)\n",
    "        y_pred = classif.predict(X_test)\n",
    "        \n",
    "        accuracy[i] = classif.score(X_test, y_test)\n",
    "        f1[i] = metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "        precision[i] = metrics.precision_score(y_test, y_pred)\n",
    "        recall[i] = metrics.recall_score(y_test, y_pred)\n",
    "    print(\"Done\")\n",
    "    return accuracy,f1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_names = [\"Logistic Regression\", \"LDA\", \"KNN 5\", \"KNN 10\", \"GNB\", \"DT\", \"SVM\", \"RFC\", \"XGB\"]\n",
    "classifiers = [LogisticRegression(max_iter=2048), LinearDiscriminantAnalysis(),KNeighborsClassifier(n_neighbors=5), KNeighborsClassifier(n_neighbors=10),GaussianNB(),DecisionTreeClassifier(),SVC(kernel='linear',random_state=random_state),RandomForestClassifier(),XGBClassifier(use_label_encoder=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_test_imp = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,f1,precision,recall = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sm,f1_sm,precision_sm,recall_sm = try_all_classifiers(scaler.transform(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaler.transform(X_train_imp),scaler.transform(imputer.transform(X_test)),Y_train,Y_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rus,f1_rus,precision_rus,recall_rus = try_all_classifiers(X_train_imp,X_test_imp,Y_train,Y_test, classifiers, sampling = \"SMOTEENN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print('''\n",
    "| classifier          | Accuracy | Precision | Recall | F1 score |\n",
    "| =================== | ======== | ========= | ====== | ======== |''')\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy,precision,recall,f1):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "    \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_sm,precision_sm,recall_sm,f1_sm):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "  \n",
    "print(\"\\n===============================================================\\n\")\n",
    "for c,a,p,r,f in zip(classifiers_names,accuracy_rus,precision_rus,recall_rus,f1_rus):\n",
    "    print(c,\"  |  \",a,\"  |  \",p,\"  |  \",r,\"  |  \",f,\"  |  \")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y_incomp_realmiss_train.npy\",X_train_imp)\n",
    "np.save(\"y_incomp_realmiss_test.npy\",X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp = np.load('y5_incomp_realmiss_train.npy')\n",
    "#display(np.all(arr == X_train_imp))\n",
    "\n",
    "X_test_imp = np.load('y5_incomp_realmiss_test.npy')\n",
    "#display(np.all(arr == X_test_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
