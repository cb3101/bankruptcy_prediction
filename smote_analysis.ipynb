{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  \n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = arff.loadarff(r\"C:\\Users\\CHIRAG\\Desktop\\sem_6\\mtl782\\dataset\\\\3year.arff\")\n",
    "data = pd.DataFrame(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5618\n",
      "10503\n",
      "(10503, 65)\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().any(axis = 1).sum())\n",
    "print(len(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    for i in range(64):\n",
    "        name = \"Attr\" + str(i+1)\n",
    "        df[name] = pd.to_numeric(df[name], errors='coerce', downcast = \"float\")\n",
    "    df['class'] = df['class'].astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing : Replacing NA with Mean, Scaling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na_mean(df):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_data = imp.fit_transform(df)\n",
    "    return pd.DataFrame(imp_data, index=df.index, columns=df.columns)\n",
    "def scaling(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[:-1] = scaler.fit_transform(df[:-1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = replace_na_mean(data)\n",
    "data = scaling(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = data.loc[data['class'] == 0]\n",
    "data1 = data.loc[data['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "X0,y0 = data0.iloc[:,:-1], data0.iloc[:,-1]\n",
    "X1,y1 = data1.iloc[:,:-1], data1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def apply_pca(df, n_comp):\n",
    "    pca = PCA(n_components= n_comp)\n",
    "    principalComponents = pca.fit_transform(df)\n",
    "    return pd.DataFrame(principalComponents)\n",
    "X = apply_pca(X,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_classifiers(X,y, classifiers, sampling  = None):\n",
    "    accuracy = [0]*len(classifiers)\n",
    "    f1 = [0]*len(classifiers)\n",
    "    precision = [0]*len(classifiers)\n",
    "    recall = [0]*len(classifiers)\n",
    "    i = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=1, shuffle = True)\n",
    "    if sampling == \"SMOTE\":\n",
    "        smote = SMOTE()\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"SMOTE\")\n",
    "    if sampling == \"RUS\":\n",
    "        rus = RandomUnderSampler()\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"RUS\")\n",
    "    \n",
    "    for i in range(len(classifiers)):\n",
    "        classif = classifiers[i]\n",
    "        classif.fit(X_train, y_train)\n",
    "        y_pred = classif.predict(X_test)\n",
    "        \n",
    "        accuracy[i] = classif.score(X_test, y_test)\n",
    "        f1[i] = metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "        precision[i] = metrics.precision_score(y_test, y_pred)\n",
    "        recall[i] = metrics.recall_score(y_test, y_pred)\n",
    "    print(\"Done\")\n",
    "    return accuracy,f1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_names = [\"Logistic Regression\", \"LDA\", \"KNN 5\", \"KNN 10\", \"GNB\", \"DT\", \"SVM\", \"RFC\", \"XGB\"]\n",
    "classifiers = [LogisticRegression(), LinearDiscriminantAnalysis(),KNeighborsClassifier(n_neighbors=5), KNeighborsClassifier(n_neighbors=10),GaussianNB(),DecisionTreeClassifier(),SVC(),RandomForestClassifier(),XGBClassifier(use_label_encoder=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy,f1,precision,recall = try_all_classifiers(X,y, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE\n",
      "[17:45:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy_sm,f1_sm,precision_sm,recall_sm = try_all_classifiers(X,y, classifiers, sampling = \"SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUS\n",
      "[17:46:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy_rus,f1_rus,precision_rus,recall_rus = try_all_classifiers(X,y, classifiers, sampling = \"RUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9550602147614518\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle = True)\n",
    "model = BaggingClassifier(base_estimator= DecisionTreeClassifier(), n_estimators=20, random_state=7)\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515379457206288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "model = AdaBoostClassifier(n_estimators=20, random_state= seed)\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527757691087853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "seed = 6\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "model4 = KNeighborsClassifier(n_neighbors=10)\n",
    "estimators.append(('knn', model4))\n",
    "model5 = GaussianNB()\n",
    "estimators.append(('gnb', model5))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Logistic Regression', 'LDA', 'KNN 5', 'KNN 10', 'GNB', 'DT',\n",
       "        'SVM', 'RFC', 'XGB'],\n",
       "       ['0.9574738178356077', '0.9552523008568709', '0.9552523008568709',\n",
       "        '0.9574738178356077', '0.9552523008568709', '0.9165344335131704',\n",
       "        '0.9574738178356077', '0.9565217391304348', '0.9562043795620438'],\n",
       "       ['0.6172643605204697', '0.6648682957791178', '0.7483338622659473',\n",
       "        '0.7258013329101872', '0.9562043795620438', '0.8540145985401459',\n",
       "        '0.9574738178356077', '0.9247857822913361', '0.902253252935576'],\n",
       "       ['0.5483973341796256', '0.6667724531894637', '0.5963186290066645',\n",
       "        '0.6724849254205014', '0.952078705172961', '0.6385274516026658',\n",
       "        '0.9574738178356077', '0.6940653760710885', '0.6969216121866074']],\n",
       "      dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_table = np.vstack((classifiers_names, accuracy, accuracy_sm, accuracy_rus))\n",
    "display(accuracy_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Logistic Regression', 'LDA', 'KNN 5', 'KNN 10', 'GNB', 'DT',\n",
       "        'SVM', 'RFC', 'XGB'],\n",
       "       ['0.0', '0.0', '0.013986013986013986', '0.0',\n",
       "        '0.013986013986013986', '0.1488673139158576', '0.0',\n",
       "        '0.16969696969696968', '0.21590909090909088'],\n",
       "       ['0.10267857142857142', '0.11557788944723618',\n",
       "        '0.09371428571428571', '0.09243697478991598', '0.0',\n",
       "        '0.1726618705035971', '0.0', '0.23300970873786406',\n",
       "        '0.20207253886010365'],\n",
       "       ['0.08252740167633785', '0.12353923205342236',\n",
       "        '0.09272467902995722', '0.10104529616724738',\n",
       "        '0.013071895424836602', '0.12720306513409962', '0.0',\n",
       "        '0.15734265734265734', '0.15561450044208666']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_table = np.vstack((classifiers_names, f1, f1_sm, f1_rus))\n",
    "display(f1_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Logistic Regression', 'LDA', 'KNN 5', 'KNN 10', 'GNB', 'DT',\n",
       "        'SVM', 'RFC', 'XGB'],\n",
       "       ['0.0', '0.0', '0.1111111111111111', '0.0', '0.1111111111111111',\n",
       "        '0.13142857142857142', '0.0', '0.45161290322580644',\n",
       "        '0.4523809523809524'],\n",
       "       ['0.05702479338842975', '0.06509433962264151',\n",
       "        '0.0553306342780027', '0.05378973105134474', '0.0',\n",
       "        '0.11374407582938388', '0.0', '0.2057142857142857',\n",
       "        '0.15476190476190477'],\n",
       "       ['0.04516584333098095', '0.06954887218045112',\n",
       "        '0.051261829652996846', '0.05719921104536489',\n",
       "        '0.05263157894736842', '0.07087959009393681', '0.0',\n",
       "        '0.0891089108910891', '0.08826479438314945']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_table = np.vstack((classifiers_names,precision, precision_sm, precision_rus))\n",
    "display(precision_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Logistic Regression', 'LDA', 'KNN 5', 'KNN 10', 'GNB', 'DT',\n",
       "        'SVM', 'RFC', 'XGB'],\n",
       "       ['0.0', '0.0', '0.007462686567164179', '0.0',\n",
       "        '0.007462686567164179', '0.17164179104477612', '0.0',\n",
       "        '0.1044776119402985', '0.1417910447761194'],\n",
       "       ['0.5149253731343284', '0.5149253731343284',\n",
       "        '0.30597014925373134', '0.3283582089552239', '0.0',\n",
       "        '0.3582089552238806', '0.0', '0.26865671641791045',\n",
       "        '0.291044776119403'],\n",
       "       ['0.47761194029850745', '0.5522388059701493',\n",
       "        '0.48507462686567165', '0.43283582089552236',\n",
       "        '0.007462686567164179', '0.6194029850746269', '0.0',\n",
       "        '0.6716417910447762', '0.6567164179104478']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall_table = np.vstack((classifiers_names,recall, recall_sm, recall_rus))\n",
    "display(recall_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
